---
title: "Mise en oeuvre de MLOPS dans un cas d'√©tude d'analyse de sentiments de Tweets"
date: "2024-11-28"
tags: ["Language modelling", "GitHub", "VS Code", "MLFlow"]
categories: ["Partage d'exp√©rience"]
author: "C√©cile"
---

# La mission et le contexte

## Le sujet : Analyse de sentiments

Un client dans le domaine du transport a√©rien nous a demand√© un prototype fonctionnel d'un mod√®le permettant de d√©tecter les tweets √† connotation n√©gative. Cette probl√©matique li√©e √† la mod√©lisation du langage (Natural Language Processing ou NLP) est d√©j√† largement √©tudi√©e. On trouve pour y r√©pondre un arsenal de biblioth√®ques, de mod√®les sp√©cifiquement entrain√©s, voire de services enti√®rement packag√©s.<br>
J'ai test√© diff√©rentes approches avec un objectif focalis√© autant sur l'exactitude de pr√©diction (l'accuracy) que sur le temps d'entrainement et le temps de r√©ponse du mod√®le une fois d√©ploy√©.<br>
L'objectif de cet article est d'illustrer comment MLOPS nous aide dans une d√©marche d'√©laboration et de mise en production d'un mod√®le. Je n'ai pas d√©taill√© le travail de conception Machine Learning/Deep Learning dans dans le cadre du NPL (Language Natural Processing) mais il y a j'esp√®re suffisament d'encarts d'information pour que les non sp√©cialistes s'y retrouvent üòú.


## Les outils : Biblioth√®ques d'analyse, m√©thodes de mod√©lisation du langage

Afin de pouvoir mener un calcul de classification il nous faut transformer le texte en chiffres, ou plut√¥t en vecteurs. De fa√ßon intuitive on imagine qu'en associant une connotation plus ou moins n√©gative √† chaque mot on peut arriver √† donner un score √† une phrase.<br>

![alt text](image-24.png)
<i> Mod√©lisation par comptage de mots </i>

<span style="background-color: #0056b3; color: white; padding: 10px; display: block;">
    <b>
    Les m√©thodes utilis√©es avant le machine learning, bas√©es sur des dictionnaires associant chaque mot √† un score sont encore utilis√©es. J'ai pu tester SentimentIntensityAnalysis (NLTK) et TextBlob.<br>
    De fa√ßon plus √©labor√©e on peut repr√©senter chaque mot unique (token) par un vecteur dont les composantes sont ses occurences dans les diff√©rents tweets (comptage simple) ou encore le rapport entre sa fr√©quence dans un tweet et celle dans l'ensemble des tweets de l'√©chantillon (m√©thode TFIdF). Les mod√©lisation utilis√©es sont CountVectorizer et TFIdF.<br>
    Viennent ensuite des m√©thodes plus √©labor√©es n√©cessitant la mise en oeuvre de r√©seaux de neurones: pour r√©aliser la mod√©lisation des mots on va consid√©rer leur contexte (les mots pr√©c√©dents et suivants, les diff√©rentes phrases), selon une certaine fen√™tre et certaines conditions d'apparition.Les mod√®les les plus r√©cents permettent de donner plus d'importance √† certaines associations de mots (m√©canisme d'attention). J'ai explor√© successivement Word2Vec, GloVE, USE, Bert, et une variation Roberta sp√©cialis√©e dans l'analyse de tweet. <br></b>
</span>

## La m√©htodologie : MLOPS

![alt text](image.png)
<i> Boucle sans fin du MLOPS </i>

A l'instar de DeOps, MLOps est le trait d'union entre les d√©veloppeurs et l'op√©rationnel, int√©grant en plus la boucle de Machine Learning. Les √©tapes sont clairement d√©finies mais quel est l'enjeu et qu'est-ce que cela implique?

### Principes de MLOPS

1 - Automatisation
Au d√©part, le processus de mise en ≈ìuvre d'un mod√®le est manuel et it√©ratif, incluant la pr√©paration, la validation des donn√©es, et la cr√©ation de mod√®les.<br>
Une fois automatis√©, le mod√®le se forme et se recycle de mani√®re continue, en validant les nouvelles donn√©es d√®s leur disponibilit√©.<br>
L'automatisation du pipeline CI/CD (Int√©gration continue/D√©veloppement continu)permet d'int√©grer et de d√©ployer des mod√®les ML de mani√®re continue et sans intervention manuelle.

2 - Int√©gration continue
L'int√©gration continue permet de valider les tests, les donn√©es, les sch√©mas et les mod√®les, tout en d√©ployant automatiquement des pipelines ML ou en annulant les modifications non d√©sir√©es.

3 - Reproductibilit√©
Stockage de la conception, du traitement des donn√©es, de la formation du mo√®dle, du d√©ploiement afin que les mod√®les soient facilement reproduits.

### Avantages de MLOPS

- L'automatisation des processus permet le d√©ploiement rapide d'un grand nombre de mod√®les
- Productivit√© am√©lior√©e gr√¢ce √† la collaboration et √† la r√©utilisation des mod√®les
- Les mod√®les non d√©ploy√©s peuvent √™tre valoris√©s 
- Les mod√®les peuvent √™tre surveill√©s et actualis√©s 
- Plus de r√©ussite dans les projets gr√¢ce √† l'int√©gration, au d√©ploiement, √† la livraison, la surveillance et les tests continus des mod√®les

### Outils choisis
- Pipeline de donn√©es: Automatis√© dans un notebook<br>

![alt text](image-7.png)
![alt text](image-9.png)
![alt text](image-8.png)
<i> Interface MLFLOW: Exp√©rimentations, m√©triques et art√©facts logg√©s </i>

- Pipeline ML: MLFlow utilis√© √† la fois pour l'enregistrement des exp√©rimentation et des r√©sultats et pour le registre de mod√®les.<br>
- Pipeline d'application: Avec un dossier de travail configur√© comme d√©p√¥t local Git, Visual Studio Code poss√®de l'ensemble des extensions permettant de visualiser les modifications du code et de g√©rer le versionning, puis dans les √©tapes de d√©veloppement de r√©aliser les tests. L'application est d√©ploy√©e via un workflow Github actions.<br>

# √âtape 1 : Analyse et pr√©paration des donn√©es

N'ayant pas de donn√©es client j'ai utilis√© un jeu de donn√©es [Open Source](https://www.kaggle.com/datasets/kazanova/sentiment140) contenant 1 600 000 tweets √©tiquet√©s postif/n√©gatif de fa√ßon √©quilibr√©e. 

## S√©lection du jeu de donn√©es

Afin de couvrir le vocabulaire m√©tier les tweets utilisant les termes typiques du transport a√©rien on √©t√© s√©lectionn√©s. J'ai ensuite appliqu√© LanguageDectector (Spacy) pour limiter aux tweets en langue anglaise. Apr√®s r√©-√©quiilibrage par √©limination j'ai un jeu de donn√©es de 6 473 tweets.

## Nettoyage

Il n'y a pas de valeurs manquantes par contre des doublons ont √©t√© d√©tect√©s. J'ai supprim√© ceux pouvant cr√©er une confusion lors de la mod√©lisaton: par exemple ceux ayant le m√™me contenu textuel mais qui ont √©t√© jug√©s soit positif soit n√©gatif. Il y a √©galement les messages identiques multiples d'un m√™me auteur (un seul a √©t√© pr√©serv√©) qui peuvent biaiser les mod√©lisations par comptage de mots.

## Pr√©-traitement

Cette partie est particuli√®rement utile pour les m√©thodes dont le temps de calcul et la taille des matrices r√©sultantes d√©pendent de la taille du vocabulaire, typiquement les m√©thodes classiques par comptage. <br>
Les m√©thodes plus r√©centes poss√®de des outils de pr√©traitement, surtout la tokenisation - r√©ductions √† des mots uniques. Il est utile de r√©aliser ces √©tapes manuellement afin de pouvoir dimensionner par exemple la taille √† choisir pour l'homog√©n√©isation des tenseurs en entr√©e des m√©thodes les plus √©labor√©es comme WordToVec ou Bert (le padding) ou encore dimensionner la taille maximale des s√©quences en entr√©e des r√©seaux de neurones. 

### Traitement du "langage tweet" 

Les tweets constituent une variante du langage commun avec des expressions exacerb√©es (r√©p√©titions), imag√©es (√©comticon) et l'utilisation de hashtags, d'url, de citations. Pour chaque √©tape il faut juger si le texte concern√© peut avoir une valeur informative. Voici ce qui a √©t√© appliqu√©:

- D√©tection des expressions h√©rit√©es de html g√©n√©r√©es lors du passage en texte brut (ex: &Amp)
- Remplacement des url et des citations par des balises <url> et <mention> <br>
        Original: was totally crushed when I found that much looked forward to plane read: Air Kisses by @zotheysay, had sold out at airport <br>
        <span style="color: darkgreen;">Modifi√©: was totally crushed when I found that much looked forward to plane read: Air Kisses by <mention>, had sold out at airport</span>
        
- R√©duction de la r√©p√©tition des caract√®res, dans cet exemple les points d'exclamation<br>
        Original: Sitting in the airport, waiting for the plane to arrive, so we can depart!!!   http://twitpic.com/6ebzo<br>
        <span style="color: mediumspringgreen;">Modifi√©: Sitting in the airport, waiting for the plane to arrive, so we can depart!!  <url></span>


- Utilisation de dictionnaires d'abbr√©viations, d'expression d'argot et d'emoticons pour interpr√©ter les caract√®res
- Suppression des caract√®res sp√©ciaux r√©siduels (@, #, caract√®res non ASCII)
- Expansion des contractions et application d'un correcteur d'orthographe (languagetoolPython)
        Original: @DavidArchie Hope you, your team, Cookie &amp; his crew have a safe trip home! You guys are all amazing! Hope you'll get some R&amp;R time now.<br>
        <span style="color: forestgreen;">Modifi√©: <mention> Hope you, your team, Cookie & his crew have a safe trip home! You guys are all amazing! Hope you will get some Randy time now.</span>
 
L'application de l'ensemble de ces fonctions sur les tweets s√©lectionn√©s est rapide gr√¢ce √† l'utilisation de biblioth√®ques et aux expressions r√©guli√®res (3'40").<br>         

### R√©duction du vocabulaire

La tokenisation des textes de tweets apr√®s les premiers traitements conduit √† un vocabulaire de plus de 12 000 termes qu'il faut chercher √† r√©duire pour r√©duire la taille des matrices.<br>
La suppression de certains signes de ponctuation non informatifs (, . ; :) et une lemmatisation (regroupement des termes ayant la m√™me racine) permet de r√©duire le vocabulaire de 25%.

## Feature engineering

J'ai utilis√© un encodeur √©tudi√© sp√©cifiquement pour l'analyse de sentiments. SentimentIntensityAnalyser (SIA de NLTK) attribue un score de sentiment √† une une phrase, en combinant simplement les scores de chaque mot de la phrase. Voici un example avec un tweet brut, apr√®s nettoyage, apr√®s tokenisation/lemmatisation:<br>

![alt text](image-1.png)
![alt text](image-2.png)
![alt text](image-4.png)

<i>Score SIA d'une phrase exemple selon l'√©tape de pr√©-traitement </i>

## M√©trique adapt√©e √† la probl√©matique m√©tier

Le client souhaite d√©tecter les "bad buzz" donc les sentiments n√©gatifs en priorit√©. J'ai donc d√©fini le score de sentiment n√©gatif (initialement 0) comme la classe positive(1) et le score de sentiment positif (initialement 4) comme la classe n√©gative (0).<br>
La m√©trique principale sera bien s√ªr l'exactitude globale (accuracy) et pour des performances √©quivalentes il faudra examiner le rappel (recall) qui est le taux de pr√©diction positives correctes et donc minimise les faux n√©gatifs.

## Baseline

<img src="image-5.png" alt="Matrice de confusion SIA" width="300" height="300">
<img src="image-6.png" alt="Rapport de classification SIA" width="300" height="150"><br>
<i> Matrice de confusion et rapport de classifcation des valeurs de score SIA vs √©tiquettes r√©elles </i> <br> 
<br>
En comparant la colonne de score SIA aux √©tiquettes r√©elles on obtient une accuracy de 0,66. Par contre la matrice de confusion montre que la classe 1 (sentiment n√©gatif) est moins bien pr√©dite que la classe 0.<br>
<br>

# √âtape 2 : Mod√©lisation

## Approche classique

### API sur √©tag√®re
En premi√®re approche j'ai test√© le service [Azure AI Language](https://azure.microsoft.com/en-us/products/ai-services/ai-language?msockid=366d561faaeb6ac416084323ab526ba8). La performance est tout juste sup√©rieure √† la baseline, avec √©galement une disparit√© entre les classes. Bien que la documentation du service ne fournisse pas de d√©tail, les mod√®les utilis√©s sont bas√©s sur Bert avec des pr√©traitements. Cela nous prouve que le probl√®me n'est pas trivial ! üò£

### Optimisation automatique 

#### AutoML (sans GPU -> pas de deep learning)

Azure fournit √©galement un service d'optimisation automatique √† partir des donn√©es textes vers une classification. Le mod√®le le plus performant est un ensemble constitu√© de diff√©rentes r√©gressions logistiques et de SVM appliqu√© sur une mod√©lisation du texte par TfIdF. L'exactituce atteinte est de 0,75. <br>
<br>
![alt text](image-10.png)<br>
<i> M√©triques du meilleur mod√®le AutoML </i>
<br>
<br>
Il est possible de sauvegarder le mod√®le et le code python utilis√© pour sa mise au point, par contre l'environnement n√©cessaire est complexe et tr√®s d√©pendant de Azure. N√©anmoins cet exp√©rimentation nous montre la voie vers le type d'embedding et d'algorithme les plus adapt√©s √† notre probl√®me.

#### Pycaret (on peut utiliser aussi AutoSKLearn)

Pycaret permet d'explorer rapidement un ensemble complet d'algorithmes de classification √† partir de jeux de donn√©es avec s√©paration train/test.Il poss√®de une fonctionnalit√© de log automatique dans MLFlow ainsi que l'ensemble des √©tapes de mise au point d'un mod√®le √† l'aide de commandes simples.<br>

![alt text](image-13.png)
<i> Suivi d'exp√©rimentation MLFlow des algorithmes de classification test√©s par Pycaret depuis un embedding CountVectorizer du texte pr√©trait√© </i><br>


Le mod√®le de stacking combinant Extra Trees, SVM et R√©gression logistique a les meilleures performances par contre son entrainement 75 fois plus long que les mod√®les simples comme la r√©gression logistique ; il risque d'√™tre peu r√©actif en production.<br>
Au final la r√©gression logistique apparait une fois de plus comme une solution int√©ressante. Une repr√©sentation en projection NCA montre que pour ce classifieur les erreurs sont situ√©es √† la fronti√®re entre les classes et non pas al√©atoirement r√©parties<br>

![alt text](image-14.png)<br>
<i>Projection NCA d'une classification par r√©gression logistique </i>

#### Optimisation de la r√©gression logistique

Soyons imaginatif: la r√©gression logistique est plut√¥t efficace et nous avons par ailleurs l'information de score de sentiment.<br>
Quelques essais de param√®tres de la r√©gression logistique et le pipeline est pr√™t. M√™me en utilisant la colonne de texte sans pr√©-traitement les performances sont presque aussi bonnes sur l'√©chantillon de test que AutoML et un recall de 0,76 sur la classe 1, plut√¥t bien pr√©dite.<br>

<img src="image-15.png" alt="Matrice de confusion SIA" width="400" height="300">
<img src="image-16.png" alt="Rapport de classification SIA" width="250" height="110"><br>
<i>Matrice de confusion et rapport de classification du mod√®le combinant r√©gression logistique et SIA </i>

### Enregistrement d'un mod√®le

Le registre de mod√®les de MLFlow permet de pouvoir utiliser le mod√®le lors de phases ult√©rieures de d√©ploiement. En enregistrant le mod√®le avec une signature et un sch√©ma de donn√©es d'entr√©e et de sortie il sera bien document√© et pr√™t √† l'emploi gr√¢ce aux fonctions de chargement de la biblioth√®que mlflow.

![mod√®le enregistr√© dans MLFlow](mlflow_model.png)
<i> Mod√®le complet enregistr√© dans MLFlow </i> <br>

Comme le serveur MLFlow local est utilis√© une copie des fichiers du mod√®le est enregistr√©e dans un conteneur de stockage en ligne afin de pouvoir √™tre servie en production.

## Mod√®les avanc√©s

<span style="background-color: #0056b3; color: white; padding: 10px; display: block;">
    <b>
Alors que la premi√®re partie concernait des mod√©lisations du corpus de documents par comptage de mots ou de grammes, les mod√®les de cette seconde partie reposent sur des mod√©lisations de langage tenant compte du contexte des mots. Pour stocker ces donn√©es une matrice en deux dimensions n'est pas suffisante: on utilise des tenseurs, c'est-√†-dire des matrices de donn√©es √† dimensions multiples, cette premi√®re √©tape n√©cessite d√©j√† des reseaux de neurones. Ensuite le mod√®le lui-m√™me apporte ses traitements √©galement par r√©seaux de neurones et enfin il faut ajouter une couche de sortie selon l'objectif vis√©, ici une classification binaire qui peut √™tre int√©gr√©e dans le mod√®le ou effectu√© √† posteriori.<br>
Le r√©-entrainement complet des mod√®les n'est pas recommand√© surtout avec un faible volume de donn√©es par contre on peut envisager d'extraire les embeddings aplatis en 2D (transfer learning) pour effectuer une tache de classification ou de r√©-entrainer partiellement en figeant des couches.<br></b>
</span>
<br>

![alt text](image-17.png)
<i> Principe g√©n√©ral des mod√®les avanc√©s (deep learning) </i>

### Embedding Word2Vec

<span style="background-color: #0056b3; color: white; padding: 10px; display: block;">
    <b>
    L'embedding de Word2Vec encode les phrases en prenant en compte pour chaque mot le contexte dans une fen√™tre d√©finie. J'ai choisi un fen√™tre de 5 mots et la m√©thode skip-gram (pr√©diction d'un mot en fonction du contexte) pour effectuer un embedding en dimension 300 depuis le texte pr√©trait√©. Cet embedding se fait avec le mod√®le Word2Vec (Gensim) pr√©-entrain√© sur un large corpus. <br></b>
</span>
<br>

Une fois l'embedding r√©alis√© j'ai test√© la capacit√© de traitement avec un r√©seau de neurones mettant en oeuvre LSTM pour aboutir √† une classification des phrases. Gr√¢ce √† MLFlow j'ai obtenu imm√©diatement une comparaison des mod√®les:<br>

![alt text](image-19.png)
<i>Utilisation de la fonction compare de MLFlow </i><br>

Malgr√© l'utilisation de l'ensemble des techniques r√©duisant le sous- et le sur-apprentissage (couches denses interm√©diaires, doublement de la couche LSTM, dropout, r√©gularisation) les r√©sultats sont moyens. Le meilleur mod√®le utilise LSTM bi-directionnel, je l'ai optimis√© automatiquement (structure et param√®tres) gr√¢ce √† Keras tuner mais les r√©sultats sont moins bons que le mod√®le retenu dans l'approche classique.

## Embedding Glove

<span style="background-color: #0056b3; color: white; padding: 10px; display: block;">
    <b>
    L'embedding Glove combine les avantages de Word2Vec (prise en compte du contexte local) et des mod√®les de comptage en calculant des co-occurences dans l'ensemble du corpus. De fa√ßon similaire √† Word2Vec l'embedding est r√©alis√© avec le mod√®le pr√©-entrain√© et sert de couche d'embedding √† un mod√®le sur mesure de deep learning.  <br></b>
</span>
 <br>
Cet embedding a √©t√© test√© avec un r√©seau de neurones de structure similaire √† celui mis au point pour Word2Vec et optimis√© avec Keras Tuner. Les r√©sultats sont meilleur (val_accuracy 0.72 pour 0.7 avec Word2Vec).

## USE

<span style="background-color: #0056b3; color: white; padding: 10px; display: block;">
    <b>
USE produit des repr√©sentations contextuelles qui tiennent compte de l'ensemble de la phrase, non pas seulement des mots ce qui lui permet de capturer les relations contextuelles et s√©mantiques. Il est tr√®s facile √† mettre en oeuvre via Tensorflow Hub  <br></b>
</span>
 <br>

En utilisant USE comme une boite noire et en ajustant ses poids √† nos donn√©es on a imm√©diatement un r√©sultat de l'ordre des meilleurs mod√®les de l'approche classique (accuracy_test 0.74).<br>

## Bert

Malgr√© la bonne performance de USE l'utilisation des moyens du deep learning (GPU) n'a pas vraiment am√©lior√© ce qui avait √©t√© obtenu avec l'approche classique. Essayons une des m√©thodes les plus r√©centes. <br>

<span style="background-color: #0056b3; color: white; padding: 10px; display: block;">
    <b>
BERT (Bidirectional Encoder Representations from Transformers) est con√ßu pour comprendre le contexte des mots de fa√ßon bi-directionnelle. Il utilise un m√©canisme d'attention pour comprendre les relations entre les mots de la phrase. Le pr√©-entrainement inclut la pr√©diction de mots masqu√©s et l'√©tablissement de relations entre les phrases. <br></b>
</span>
 <br>
La flexibilit√© et la puissance de Bert nous permettent d'envisager plusieurs utilisations:<br>
-  Transfer learning et ajoutant une couche dense de classification entrainable au mod√®le pr√©-entrain√©.<br>
-  Utilisation des embeddings (derni√®re couche cach√©e) comme entr√©e d'un classifieur<br>
-  Fine-tuning avec le jeu de donn√©es<br>

Un simple r√©-entrainement depuis un mod√®le pr√©-entrain√© est rapide (3'40") et am√®ne un progr√®s imm√©diat avec une pr√©diction correcte √† plus de 80%.<br>

![alt text](image-20.png)<br>
<i>R√©sultat du mod√®le Bert pr√©-entrain√© (jeu de test)</i>

C'est la solution qui sera retenue car diff√©rents classifieurs appliqu√©s sur l'embedding extrait de la derni√®re couche cach√©e conduit au m√™me r√©sultat avec un temps de calcul plus long et le mod√®le fine-tun√© permet de gagner 1% mais n√©cessite presque 2h d'entrainement.

## Roberta (mod√®le twitter-roberta-base-sentiment)

Avec une variante de Bert entrain√© sp√©cifiquement avec des tweet la version pr√©-entrain√©e donne un r√©sultat banal, mais le fine-tuning de l'ordre de 80% permet de mieux pr√©dire la classe 1 (sentiment n√©gatif) que la classe 0.<br>

# √âtape 3 : D√©ploiement

Le mod√®le Bert pr√©-entrain√© n'a pas pu √™tre d√©ploy√© sur la solution choisie (Azure compte gratuit) qui octroit 1 Go de stockage ce qui n'est pas suffisant pour importer les biblioth√®ques n√©cessaires √† l'ex√©cution du mod√®le plus le chargement du mod√®le lui-m√™me.<br>
J'ai donc d√©ploy√© le mod√®le combinant la r√©gression logistique avec SIA.

## Pipeline de d√©ploiement continu

![alt text](image-21.png)

En local, une fois les tests d'accessibilit√© du mod√®le et de son fonctionnement r√©alis√©s dans l'environnement de travail, un environnement d√©di√© a √©t√© cr√©√© pour reproduire celui en production. <br>
Les tests unitaires ont √©t√© effectu√©s dans cet environnement de test puis int√©gr√©s dans le script de d√©ploiement dans Github actions pour conditionner le d√©ploiement √† la r√©ussite des tests.<br>
Dans l'environnement de production le mod√®le est dans un stockage mont√© directement dans la ressource d'ex√©cution. Le d√©ploiement se fait de mani√®re automatis√©e depuis Github.<br>
Enfin une ressource Application Insight a √©t√© cr√©√©e afin de capturer les √©v√©nements. Gr√¢ce √† l'utilisation de Opentelemetry depuis l'application cela fonctionne √©galement depuis l'environnement local.

## Tests unitaires
Cinq groupes de tests ont √©t√© mis en place:
1. Disponibilit√© du mod√®le: V√©rifie la pr√©sence du conteneur dans l'espace de stockage et la pr√©sence des fichiers n√©cessaires √† son ex√©cution
2. Mod√®le: Passe en mode test et v√©rifie que le mod√®le ne se charge pas
3. Test de l'app: en mode test instancie un mock qui simule un mod√®le et teste le predict de l'app.
4. Test des routes: dans le m√™me contexte que le test pr√©c√©dent, v√©rifie les autres routes et que l'absence de texte conduit √† une erreur
5. Test de logging: G√©n√®re des traces qui doivent √™tre captur√©es par Azure Application Insight

üí°Le passage en mode test √† travers une variable d'environnement permet d'√©viter de charger le mod√®le et de reproduire un chemin local. Cela est particuli√®rement utile pour les tests dans Github Actions.

## API d√©ploy√©e [Analyse de sentiment des tweets](https://tweetsentimentanalysiseco-fuetaqf3hbezegch.francecentral-01.azurewebsites.net/)

[![PLan de d√©ploiement](image-22.png)]([URL/de/la/page/cible](https://tweetsentimentanalysiseco-fuetaqf3hbezegch.francecentral-01.azurewebsites.net/))


L'API utilise DeepTranslator (Google), accepte jusqu'√† 500 caract√®res et supporte tout types de caract√®res. Des tests de s√©curit√© manuels ont √©t√© men√©s, l'application traite les scripts comme des chaines - par contre j'ai √©vit√© de les stocker.

# √âtape 4 : Suivi et am√©lioration

## Performance et incidents

Le mod√®le est particuli√®rement r√©actif avec un temps de r√©ponse de l'ordre de 200-300 ms. Les volumes de transaction et le temps d'utilisation du CPU sont tr√®s faibles vu la l√©g√®ret√© du mod√®le et l'√©conomie de moyens de calcul faite en ne recourant pas aux tenseurs.

## D√©tection de pr√©visions incorrectes

Une requ√™te dans les journaux de suivi a √©t√© sauvegard√©e et est r√©-utilis√©e dans une alerte qui envoie un email d'alerte d√®s qu'il y a plus de 5 d√©tections de pr√©dictions incorrectes en 5 minutes.

## M√©canisme d'am√©lioration continue

Avec une requ√™te similaire on r√©cup√®re une fois par semaine la table compl√®te des pr√©dictions incorrectes. Une accumulation au del√† d'une certaine limite d√©clenchera le r√©-entrainement du mod√®le avec les nouvelles donn√©es ainsi collect√©es.<br>

![alt text](image-23.png)<br>
<i>Suivi des remont√©es de pr√©dictions incorrectes (cumul) </i>
<br>


# Conclusion: Takeouts du projet

D'un point de vue ML la le√ßon est claire: m√™me si du c√¥t√© du d√©veloppeur certains mod√®les √©labor√©s sont tr√®s performants, ils ne sont pas toujours adapt√©s aux exigences et au contexte de la production. <br>

La mise en oeuvre de MLOPS est une vraie √©cole de rigueur au d√©part:<br>
- il faut concevoir les trackings de fa√ßon √† pouvoir les comparer
- logger les mod√®les demande de respecter la m√©thodologie de MLFlow
- Github actions est puissant mais il faut savoir repenser les choses dans un environnement isol√©

Quand on a pass√© le temps n√©cessaire √† la mise en place de ces √©tapes le d√©ploiement devient une formalit√© üòâ